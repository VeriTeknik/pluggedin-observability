groups:
  - name: service_health
    interval: 30s
    rules:
      # Service Down Alerts
      - alert: ServiceDown
        expr: up == 0
        for: 2m
        labels:
          severity: critical
          category: availability
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} on {{ $labels.instance }} has been down for more than 2 minutes."

      # High Error Rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.05
        for: 5m
        labels:
          severity: warning
          category: errors
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "{{ $labels.service }} has error rate above 5% (current: {{ $value | humanizePercentage }})"

      # Very High Error Rate
      - alert: VeryHighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.15
        for: 2m
        labels:
          severity: critical
          category: errors
        annotations:
          summary: "Critical error rate on {{ $labels.service }}"
          description: "{{ $labels.service }} has error rate above 15% (current: {{ $value | humanizePercentage }})"

  - name: performance
    interval: 30s
    rules:
      # High Latency (p95)
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 2
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "High latency on {{ $labels.service }}"
          description: "{{ $labels.service }} p95 latency is above 2 seconds (current: {{ $value | humanizeDuration }})"

      # Very High Latency (p95)
      - alert: VeryHighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 5
        for: 2m
        labels:
          severity: critical
          category: performance
        annotations:
          summary: "Critical latency on {{ $labels.service }}"
          description: "{{ $labels.service }} p95 latency is above 5 seconds (current: {{ $value | humanizeDuration }})"

      # High Request Rate
      - alert: HighRequestRate
        expr: sum(rate(http_requests_total[5m])) by (service) > 1000
        for: 10m
        labels:
          severity: info
          category: traffic
        annotations:
          summary: "High request rate on {{ $labels.service }}"
          description: "{{ $labels.service }} is receiving more than 1000 req/s (current: {{ $value | humanize }})"

  - name: resources
    interval: 30s
    rules:
      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (
            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
          ) / node_memory_MemTotal_bytes > 0.8
        for: 5m
        labels:
          severity: warning
          category: resources
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 80% (current: {{ $value | humanizePercentage }})"

      # Critical Memory Usage
      - alert: CriticalMemoryUsage
        expr: |
          (
            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
          ) / node_memory_MemTotal_bytes > 0.9
        for: 2m
        labels:
          severity: critical
          category: resources
        annotations:
          summary: "Critical memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 90% (current: {{ $value | humanizePercentage }})"

      # High CPU Usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          category: resources
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% (current: {{ $value | humanize }}%)"

      # High Disk Usage
      - alert: HighDiskUsage
        expr: |
          (
            node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"} -
            node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"}
          ) / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"} > 0.8
        for: 5m
        labels:
          severity: warning
          category: resources
        annotations:
          summary: "High disk usage on {{ $labels.instance }}"
          description: "Disk usage on {{ $labels.mountpoint }} is above 80% (current: {{ $value | humanizePercentage }})"

  - name: database
    interval: 30s
    rules:
      # PostgreSQL Down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          category: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"

      # High Database Connections
      - alert: HighDatabaseConnections
        expr: |
          sum(pg_stat_activity_count) by (instance) /
          sum(pg_settings_max_connections) by (instance) > 0.8
        for: 5m
        labels:
          severity: warning
          category: database
        annotations:
          summary: "High database connection usage"
          description: "PostgreSQL connection usage is above 80% (current: {{ $value | humanizePercentage }})"

      # Slow Queries
      - alert: SlowQueries
        expr: rate(pg_stat_activity_max_tx_duration[5m]) > 60
        for: 5m
        labels:
          severity: warning
          category: database
        annotations:
          summary: "Slow database queries detected"
          description: "PostgreSQL has queries running longer than 60 seconds"

  - name: containers
    interval: 30s
    rules:
      # Container High CPU
      - alert: ContainerHighCPU
        expr: |
          sum(rate(container_cpu_usage_seconds_total{name!=""}[5m])) by (name) > 0.8
        for: 5m
        labels:
          severity: warning
          category: containers
        annotations:
          summary: "High CPU usage in container {{ $labels.name }}"
          description: "Container {{ $labels.name }} CPU usage is high (current: {{ $value | humanize }})"

      # Container High Memory
      - alert: ContainerHighMemory
        expr: |
          container_memory_usage_bytes{name!=""} / container_spec_memory_limit_bytes{name!=""} > 0.8
        for: 5m
        labels:
          severity: warning
          category: containers
        annotations:
          summary: "High memory usage in container {{ $labels.name }}"
          description: "Container {{ $labels.name }} memory usage is above 80%"

      # Container Restarting
      - alert: ContainerRestarting
        expr: rate(container_last_seen{name!=""}[5m]) > 0
        for: 5m
        labels:
          severity: warning
          category: containers
        annotations:
          summary: "Container {{ $labels.name }} is restarting"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last 5 minutes"

  - name: milvus
    interval: 30s
    rules:
      # Milvus Down
      - alert: MilvusDown
        expr: up{job="milvus"} == 0
        for: 2m
        labels:
          severity: critical
          category: availability
        annotations:
          summary: "Milvus is down"
          description: "Milvus instance {{ $labels.instance }} has been down for more than 2 minutes."

      # High Search Latency
      - alert: MilvusHighSearchLatency
        expr: |
          histogram_quantile(0.95,
            rate(milvus_search_latency_seconds_bucket[5m])
          ) > 2
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "High Milvus search latency"
          description: "Milvus p95 search latency is above 2 seconds (current: {{ $value | humanizeDuration }})"

      # Low Cache Hit Ratio
      - alert: MilvusLowCacheHitRatio
        expr: milvus_cache_hit_ratio < 0.8
        for: 10m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "Low Milvus cache hit ratio"
          description: "Milvus cache hit ratio is below 80% (current: {{ $value | humanizePercentage }})"

      # High Memory Usage
      - alert: MilvusHighMemory
        expr: |
          process_resident_memory_bytes{job="milvus"} /
          (1024 * 1024 * 1024) > 8
        for: 5m
        labels:
          severity: warning
          category: resources
        annotations:
          summary: "High Milvus memory usage"
          description: "Milvus is using more than 8GB memory (current: {{ $value | humanize }}GB)"